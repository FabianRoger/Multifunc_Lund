---
title: "Effect of varying number of functions and species on the slope - using species specific complementarities"
author: "Fabian Roger"
date: "`r format(Sys.Date())`"
output: github_document
---

This script produces:

+ Figure 2 b & c

(see `Effect on averaging approach` below for Figure 2 a)

This script sets up the simulations to show the effect of including a varying number of functions and (separately) a varying number of species on the slope pattern produced by the multithreshold approach. 

For the **variable number of function simulation** we hold species richness constant at `specnum`. 

We then define a set number of functions of size `funcnum` from which we draw all possible (but max 50) subsets of variable size (3 subsets-sizes total). For each subset of functions we calculate the multithreshold approach. 

For the **variable number of species simulation** we hold the number of functions constant at `funcnum` but calculate the multithreshold approach for the full species range and two smaller subsets.  


```{r, echo = FALSE, warning=FALSE, message=FALSE, "load packages"}

library(dplyr)
library(tidyr)
library(ggplot2)
#library(cowplot)
library(here)

source(here("Scripts","Multifunctionality-Simulations", "Multifunc_simulations_functions.R"))
source(here("Scripts", "MF_index_function.R"))
source(here("Scripts", "MF_Hill_function.R"))
```

# Effect on multithreshold approach

## Variable number of function simulation

### Simulate full diversity experiment

One can set the same parameters as in most other simulations:

+ `distribution` : the distribution function. The names of the parameters must be changed accordingly in `FunctionValue()`
+ `specnum` : the (maximum) number of species
+ `funcnum` : the (maximum) number of functions 
+ `method` : the method to use (with or without complementarity)

Additional parameters for `method = comp`:

+ `CF` : maximum complementarity factor 
+ `compfunc` : which functions should experience complementarity (`all` or any combination of `func.names`)
+ `r` : the *growthrate* of the complementarity factor

Here we use a maximum replication of 200 unique species combinations as otherwise the computation becomes tedious.
```{r}
set.seed(777)

specnum <- 10
funcnum <- 10

distribution = "runif"

FuncMat <- FunctionValue(specnum,funcnum, distribution, min = 0.1, max = 0.9)

func.names <- as.character( unique( FuncMat$Functions))
spec.names <- as.character( unique( FuncMat$Species))

#maxrep <- choose(specnum, floor(specnum/2))
maxrep <- 100 #using the full replications is prohibitive

SpecMat <- SpeciesMatrix(specnum = specnum, maxrep = maxrep)

method = "species_complementarity"

spec_comp <- SpecComp(specnum = specnum, funcnum = funcnum,
                     distribution = "rnorm", mean = 1, sd = 0.2,
                     spec_compfunc = func.names[1:3])

AvFunc <- AverageFunction(SpecMat, FuncMat,
                          method = method, 
                          spec_comp = spec_comp)

# set.seed(563)
# errM <- matrix(rnorm(n = nrow(AvFunc)*funcnum, mean = 0, sd = 0.01), ncol = funcnum)

#add variance
#AvFunc[,func.names] <- AvFunc[,func.names] + errM

# standardize functions 
AvFunc_func <- AvFunc %>% 
  mutate_at(vars(one_of(func.names)), function(x) {(x) / max(x)})
  #mutate_at(vars(one_of(func.names)), function(x) {(x - min(x)) / (max(x) - min(x))})

```

```{r}
AvFunc %>%
mutate(meanFunction = rowMeans(.[,func.names])) %>% 
ggplot(., aes(x = Richness, y = meanFunction))+
  geom_point()+
  geom_smooth()
```

### Variable number of function - Averaging


### simulation of all possible slopes for 1:`funcnum` functions

```{r}

# empty dataframe to store results
Slope_res_ave <- data.frame(Estimate = numeric(),
                        `Std. Error` = numeric(),
                        `t value` = numeric(),    
                        `Pr(>|t|)` = numeric(),
                        nfunc = numeric(),
                        ncomp = numeric())

# loop over all possible number of functions with complementarity
for (l in 0:funcnum) {
  
set.seed(999)

# choose method = average if no functions with complementarity and method = comp otherwise
  if(l == 0) {
    method = "av"
  }  else {
    method = "species_complementarity"
    spec_compfunc = func.names[1:l]
  }

# draw complementarity
if(l > 0) {
  set.seed(78956)
spec_comp <- SpecComp(specnum = specnum, funcnum = funcnum,
                     distribution = "rnorm", mean = 1, sd = 0.2,
                     spec_compfunc = spec_compfunc)}

# draw function values and calculate mean function for all richness levels  
AvFunc <- AverageFunction(SpecMat, FuncMat,
                          method = method,
                          spec_comp = spec_comp)
  
set.seed(563)
errM <- matrix(rnorm(n = nrow(AvFunc)*funcnum, mean = 0, sd = 0.01), ncol = funcnum)

#add variance
AvFunc[,func.names] <- AvFunc[,func.names] + errM

# standardize functions
AvFunc <- AvFunc %>% 
  select(Richness, one_of(func.names)) %>% 
  mutate_at(vars(one_of(func.names)), function(x) {x / max(x)})
  #mutate_at(vars(one_of(func.names)), function(x) {(x - min(x)) / (max(x) - min(x))})


# loop over all subsets of function of size 1:funcnum
for (i in seq_len(funcnum)) { 

  # all poosibel combination of i out of funcnum functions
  func_comb <- combn(func.names, i)
  
  # loop over all function combinations of size i
  for ( k  in seq_len(ncol(func_comb))) { 
  
    # calculate mean function
    AvFunc_temp <- AvFunc %>%
      select(Richness, one_of(func_comb[ ,k])) %>% 
      mutate(meanFunction = rowMeans(.[func_comb[ ,k]]))
  
    # fit linear model
    mod <- lm(meanFunction ~ Richness, data = AvFunc_temp)
  
    # get slope estimate
    est <- summary(mod)$coefficients[2,]
    
    # store results
    Slope_res_ave <- data.frame(t(est)) %>% 
      mutate(., nfunc = i) %>% 
      mutate(ncomp = l) %>% 
      rbind(Slope_res_ave, .)
  }
}
}


```

### Plot 
```{r, warnings = F, fig.height= 4, fig.width= 4}
plot_av <- Slope_res_ave %>% 
  filter(ncomp %in% c(0,ceiling(funcnum/3),2*ceiling(funcnum/3),funcnum)) %>% 
  ggplot(aes(x = nfunc, y = Estimate, colour = as.factor(ncomp)))+
  geom_point(position = position_jitterdodge(jitter.width = 0.2, jitter.height = 0, dodge.width = 0.75),
             alpha = 0.5, shape = 21)+
  geom_smooth( se = F, size = 0.5, 
              position = position_dodge(width = 0.5))+
  scale_color_brewer(guide = guide_legend(title = "Number of functions\nwith complementarity",
                                          nrow=2,byrow=TRUE),
                     palette = "Set1")+
  scale_x_continuous(breaks = seq(1,funcnum,1))+
 # scale_y_continuous(limits = c(NA, 0.038))+
  labs(y = "Slope estimate",
       x = "Number of functions considered")+
  ggtitle("Averaging method") +
  theme_classic()+
  theme(legend.position = "bottom")
  
 plot_av 

```


### Variable number of function - PCA multifunc

```{r}

# empty dataframe to store results
Slope_res_pca <- data.frame(Estimate = numeric(),
                        `Std. Error` = numeric(),
                        `t value` = numeric(),    
                        `Pr(>|t|)` = numeric(),
                        nfunc = numeric(),
                        ncomp = numeric())

# loop over all possible number of functions with complementarity
for (l in c(0,ceiling(funcnum/3),2*ceiling(funcnum/3),funcnum)) {
  
set.seed(999)

# choose method = average if no functions with complementarity and method = comp otherwise
  if(l == 0) {
    method = "av"
  }  else {
    method = "species_complementarity"
    spec_compfunc = func.names[1:l]
  }

# draw complementarity
if(l > 0) {
  set.seed(78956)
spec_comp <- SpecComp(specnum = specnum, funcnum = funcnum,
                     distribution = "rnorm", mean = 1, sd = 0.2,
                     spec_compfunc = spec_compfunc)}

# draw function values and calculate mean function for all richness levels  
AvFunc <- AverageFunction(SpecMat, FuncMat,
                          method = method,
                          spec_comp = spec_comp)
  
set.seed(563)
errM <- matrix(rnorm(n = nrow(AvFunc)*funcnum, mean = 0, sd = 0.01), ncol = funcnum)

#add variance
AvFunc[,func.names] <- AvFunc[,func.names] + errM

# standardize functions
AvFunc <- AvFunc %>% 
  select(Richness, one_of(func.names)) %>% 
  mutate_at(vars(one_of(func.names)), function(x) {x / max(x)})
  #mutate_at(vars(one_of(func.names)), function(x) {(x - min(x)) / (max(x) - min(x))})


# loop over all subsets of function of size 1:funcnum
for (i in seq_len(funcnum)) { 

  # all poosibel combination of i out of funcnum functions
  func_comb <- combn(func.names, i)
  
  # loop over all function combinations of size i
  for ( k  in seq_len(ncol(func_comb))) { 
  
    # calculate pca multifunc index
    AvFunc_temp <- pca_multifunc(AvFunc, vars = func_comb[ ,k]) 
    
    # fit linear model
    mod <- lm(multifunc_pca_ind ~ Richness, data = AvFunc_temp)
  
    # get slope estimate
    est <- summary(mod)$coefficients[2,]
    
    # store results
    Slope_res_pca <- data.frame(t(est)) %>% 
      mutate(., nfunc = i) %>% 
      mutate(ncomp = l) %>% 
      rbind(Slope_res_pca, .)
  }
}
}


```

### Plot 
```{r, warnings = F, fig.height= 4, fig.width= 4}
plot_pca <- Slope_res_pca %>% 
  filter(ncomp %in% c(0,ceiling(funcnum/3),2*ceiling(funcnum/3),funcnum)) %>% 
  ggplot(aes(x = nfunc, y = Estimate, colour = as.factor(ncomp)))+
  geom_point(position = position_jitterdodge(jitter.width = 0.2, jitter.height = 0, dodge.width = 0.75),
             alpha = 0.5, shape = 21)+
  geom_smooth(se = F, size = 0.5, 
              position = position_dodge(width = 0.5))+
  scale_color_brewer(guide = guide_legend(title = "Number of functions\nwith complementarity",
                                          nrow=2,byrow=TRUE),
                     palette = "Set1")+
  scale_x_continuous(breaks = seq(1,funcnum,1))+
  #scale_y_continuous(limits = c(NA, 0.038))+
  labs(y = "Slope estimate",
       x = "Number of functions considered")+
  ggtitle("PCA method")+
  theme_classic()+
  theme(legend.position = "bottom")
  
 plot_pca 

```

### Variable number of function - Sum multifunc

```{r}

# empty dataframe to store results
Slope_res_sum <- data.frame(Estimate = numeric(),
                        `Std. Error` = numeric(),
                        `t value` = numeric(),    
                        `Pr(>|t|)` = numeric(),
                        nfunc = numeric(),
                        ncomp = numeric())

# loop over all possible number of functions with complementarity
for (l in c(0,ceiling(funcnum/3),2*ceiling(funcnum/3),funcnum)) {
  
set.seed(999)

# choose method = average if no functions with complementarity and method = comp otherwise
  if(l == 0) {
    method = "av"
  }  else {
    method = "species_complementarity"
    spec_compfunc = func.names[1:l]
  }

# draw complementarity
if(l > 0) {
  set.seed(78956)
spec_comp <- SpecComp(specnum = specnum, funcnum = funcnum,
                     distribution = "rnorm", mean = 1, sd = 0.2,
                     spec_compfunc = spec_compfunc)}

# draw function values and calculate mean function for all richness levels  
AvFunc <- AverageFunction(SpecMat, FuncMat,
                          method = method,
                          spec_comp = spec_comp)
  
set.seed(563)
errM <- matrix(rnorm(n = nrow(AvFunc)*funcnum, mean = 0, sd = 0.01), ncol = funcnum)

#add variance
AvFunc[,func.names] <- AvFunc[,func.names] + errM

# standardize functions
AvFunc <- AvFunc %>% 
  select(Richness, one_of(func.names)) %>% 
  mutate_at(vars(one_of(func.names)), function(x) {x / max(x)})
  #mutate_at(vars(one_of(func.names)), function(x) {(x - min(x)) / (max(x) - min(x))})


# loop over all subsets of function of size 1:funcnum
for (i in seq_len(funcnum)) { 

  # all poosibel combination of i out of funcnum functions
  func_comb <- combn(func.names, i)
  
  # loop over all function combinations of size i
  for ( k  in seq_len(ncol(func_comb))) { 
  
    # calculate sum of functions
    AvFunc_temp <- AvFunc %>%
      select(Richness, one_of(func_comb[ ,k])) %>% 
      mutate(sumFunction = rowSums(.[func_comb[ ,k]]))
  
  
    # fit linear model
    mod <- lm(sumFunction ~ Richness, data = AvFunc_temp)
  
    # get slope estimate
    est <- summary(mod)$coefficients[2,]
    
    # store results
    Slope_res_sum <- data.frame(t(est)) %>% 
      mutate(., nfunc = i) %>% 
      mutate(ncomp = l) %>% 
      rbind(Slope_res_sum, .)
  }
}
}


```

### Plot 
```{r, warnings = F, fig.height= 4, fig.width= 4}
plot_sum <- Slope_res_sum %>% 
  filter(ncomp %in% c(0,ceiling(funcnum/3),2*ceiling(funcnum/3),funcnum)) %>% 
  ggplot(aes(x = nfunc, y = Estimate, colour = as.factor(ncomp)))+
  geom_point(position = position_jitterdodge(jitter.width = 0.2, jitter.height = 0, dodge.width = 0.75),
             alpha = 0.5, shape = 21)+
  geom_smooth( se = F, size = 0.5, 
              position = position_dodge(width = 0.5))+
  scale_color_brewer(guide = guide_legend(title = "Number of functions\nwith complementarity",
                                          nrow=2,byrow=TRUE),
                     palette = "Set1")+
  scale_x_continuous(breaks = seq(1,funcnum,1))+
  #scale_y_continuous(limits = c(NA, 0.038))+
  labs(y = "Slope estimate",
       x = "Number of functions considered")+
  ggtitle("Summing approach") +
  theme_classic()+
  theme(legend.position = "bottom")
  
 plot_sum

```

### Variable number of function - Hill multifunc

```{r}

# empty dataframe to store results
Slope_res_hill <- data.frame(Estimate = numeric(),
                        `Std. Error` = numeric(),
                        `t value` = numeric(),    
                        `Pr(>|t|)` = numeric(),
                        nfunc = numeric(),
                        ncomp = numeric())

# loop over all possible number of functions with complementarity
for (l in c(0,ceiling(funcnum/3),2*ceiling(funcnum/3),funcnum)) {
  
set.seed(999)

# choose method = average if no functions with complementarity and method = comp otherwise
  if(l == 0) {
    method = "av"
  }  else {
    method = "species_complementarity"
    spec_compfunc = func.names[1:l]
  }

# draw complementarity
if(l > 0) {
  set.seed(78956)
spec_comp <- SpecComp(specnum = specnum, funcnum = funcnum,
                     distribution = "rnorm", mean = 1, sd = 0.2,
                     spec_compfunc = spec_compfunc)}

# draw function values and calculate mean function for all richness levels  
AvFunc <- AverageFunction(SpecMat, FuncMat,
                          method = method,
                          spec_comp = spec_comp)
  
set.seed(563)
errM <- matrix(rnorm(n = nrow(AvFunc)*funcnum, mean = 0, sd = 0.01), ncol = funcnum)

#add variance
AvFunc[,func.names] <- AvFunc[,func.names] + errM

# standardize functions
AvFunc <- AvFunc %>% 
  select(Richness, one_of(func.names)) %>% 
  mutate_at(vars(one_of(func.names)), function(x) {x / max(x)})
  #mutate_at(vars(one_of(func.names)), function(x) {(x - min(x)) / (max(x) - min(x))})


# loop over all subsets of function of size 2:funcnum
for (i in 2:funcnum) { 

  # all poosibel combination of i out of funcnum functions
  func_comb <- combn(func.names, i)
  
  # loop over all function combinations of size i
  for ( k  in seq_len(ncol(func_comb))) { 
  
    # calculate sum of functions
    AvFunc_temp <- hill_multifunc(AvFunc, vars = func_comb[ ,k],
                                  scale = 1, HILL = TRUE)
  
    # fit linear model
    mod <- lm(multifunc_effN ~ Richness, data = AvFunc_temp)
  
    # get slope estimate
    est <- summary(mod)$coefficients[2,]
    
    # store results
    Slope_res_hill <- data.frame(t(est)) %>% 
      mutate(., nfunc = i) %>% 
      mutate(ncomp = l) %>% 
      rbind(Slope_res_hill, .)
  }
}
}

```

### Plot 
```{r, warnings = F, fig.height= 4, fig.width= 4}
plot_hill <- Slope_res_hill %>% 
  filter(ncomp %in% c(0,ceiling(funcnum/3),2*ceiling(funcnum/3),funcnum)) %>% 
  ggplot(aes(x = nfunc, y = Estimate, colour = as.factor(ncomp)))+
  geom_point(position = position_jitterdodge(jitter.width = 0.2, jitter.height = 0, dodge.width = 0.75),
             alpha = 0.5, shape = 21)+
  geom_smooth( se = F, size = 0.5, method ="lm",
              position = position_dodge(width = 0.5))+
  scale_color_brewer(guide = guide_legend(title = "Number of functions\nwith complementarity",
                                          nrow=2,byrow=TRUE),
                     palette = "Set1")+
  scale_x_continuous(breaks = seq(1,funcnum,1))+
  #scale_y_continuous(limits = c(NA, 0.038))+
  labs(y = "Slope estimate",
       x = "Number of functions considered")+
  ggtitle("Hill number")+
  theme_classic()+
  theme(legend.position = "bottom")
  
 plot_hill

```